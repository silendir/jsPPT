TITLE: Installing Qwen-Agent with Full Optional Dependencies (Bash)
DESCRIPTION: Installs the Qwen-Agent library from PyPI, including all optional dependencies for GUI, RAG, Code Interpreter, and MCP support. This is the recommended installation for full functionality.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/README.md#_snippet_0

LANGUAGE: bash
CODE:
```
pip install -U "qwen-agent[gui,rag,code_interpreter,mcp]"
```

----------------------------------------

TITLE: Installing Qwen-Agent with Full Dependencies (Bash)
DESCRIPTION: This command installs the latest stable version of the qwen-agent package from PyPI, including all optional dependencies for RAG, code interpreter, GUI, and MCP support.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/README_CN.md#_snippet_0

LANGUAGE: bash
CODE:
```
pip install -U "qwen-agent[rag,code_interpreter,gui,mcp]"
```

----------------------------------------

TITLE: Instantiating and Running Qwen-Agent Assistant
DESCRIPTION: This snippet demonstrates how to initialize the Qwen-Agent Assistant class with an LLM configuration, a list of available tools, a system message for role-playing and instructions, and a document for RAG. It then shows how to run the agent with a user message and iterate through the generator to process the streaming responses.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/docs/agent.md#_snippet_0

LANGUAGE: python
CODE:
```
import os
from qwen_agent.agents import Assistant
llm_cfg = {'model': 'qwen-max'}
tools = ['image_gen', 'amap_weather']  # image_gen and code_interpreter is a built-in tool in Qwen-Agent
system = 'According to the user's request, you first draw a picture and then automatically run code to download the picture ' + \
          'and select an image operation from the given document to process the image'

bot = Assistant(llm=llm_cfg,
                system_message=system,
                function_list=tools,
                files=[os.path.abspath('doc.pdf')])


messages = [{'role': 'user', 'content': 'a cute cat'}]
for response in bot.run(messages=messages):
    print('bot response:', response)
```

----------------------------------------

TITLE: Create and Run Assistant Agent (Python)
DESCRIPTION: Demonstrates how to instantiate and run an `Assistant` agent with a specific LLM configuration, system instructions, a list of available tools (including the custom 'my_image_gen' and built-in 'code_interpreter'), and access to a file. It then enters a loop to interact with the agent via a command-line interface, managing chat history and streaming responses.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/README.md#_snippet_9

LANGUAGE: Python
CODE:
```
system_instruction = '''After receiving the user's request, you should:
- first draw an image and obtain the image url,
- then run code `request.get(image_url)` to download the image,
- and finally select an image operation from the given document to process the image.
Please show the image using `plt.show()`.'''
tools = ['my_image_gen', 'code_interpreter']  # `code_interpreter` is a built-in tool for executing code.
files = ['./examples/resource/doc.pdf']  # Give the bot a PDF file to read.
bot = Assistant(llm=llm_cfg,
                system_message=system_instruction,
                function_list=tools,
                files=files)

# Step 4: Run the agent as a chatbot.
messages = []  # This stores the chat history.
while True:
    # For example, enter the query "draw a dog and rotate it 90 degrees".
    query = input('\nuser query: ')
    # Append the user query to the chat history.
    messages.append({'role': 'user', 'content': query})
    response = []
    response_plain_text = ''
    print('bot response:')
    for response in bot.run(messages=messages):
        # Streaming output.
        response_plain_text = typewriter_print(response, response_plain_text)
    # Append the bot responses to the chat history.
    messages.extend(response)
```

----------------------------------------

TITLE: Creating Custom Tool and Assistant Agent (Python)
DESCRIPTION: This Python code defines a custom tool `MyImageGen` using the `@register_tool` decorator and `BaseTool` inheritance. It then configures an LLM (either DashScope or OpenAI-compatible) and initializes an `Assistant` agent with a system message, a list of tools (including the custom one and the built-in `code_interpreter`), and a PDF file for context.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/README_CN.md#_snippet_6

LANGUAGE: python
CODE:
```
import pprint
import urllib.parse
import json5
from qwen_agent.agents import Assistant
from qwen_agent.tools.base import BaseTool, register_tool
from qwen_agent.utils.output_beautify import typewriter_print


# 步骤 1（可选）：添加一个名为 `my_image_gen` 的自定义工具。
@register_tool('my_image_gen')
class MyImageGen(BaseTool):
    # `description` 用于告诉智能体该工具的功能。
    description = 'AI 绘画（图像生成）服务，输入文本描述，返回基于文本信息绘制的图像 URL。'
    # `parameters` 告诉智能体该工具有哪些输入参数。
    parameters = [{
        'name': 'prompt',
        'type': 'string',
        'description': '期望的图像内容的详细描述',
        'required': True
    }]

    def call(self, params: str, **kwargs) -> str:
        # `params` 是由 LLM 智能体生成的参数。
        prompt = json5.loads(params)['prompt']
        prompt = urllib.parse.quote(prompt)
        return json5.dumps(
            {'image_url': f'https://image.pollinations.ai/prompt/{prompt}'},
            ensure_ascii=False)


# 步骤 2：配置您所使用的 LLM。
llm_cfg = {
    # 使用 DashScope 提供的模型服务：
    'model': 'qwen-max-latest',
    'model_type': 'qwen_dashscope',
    # 'api_key': 'YOUR_DASHSCOPE_API_KEY',
    # 如果这里没有设置 'api_key'，它将读取 `DASHSCOPE_API_KEY` 环境变量。

    # 使用与 OpenAI API 兼容的模型服务，例如 vLLM 或 Ollama：
    # 'model': 'Qwen2.5-7B-Instruct',
    # 'model_server': 'http://localhost:8000/v1',  # base_url，也称为 api_base
    # 'api_key': 'EMPTY',

    # （可选） LLM 的超参数：
    'generate_cfg': {
        'top_p': 0.8
    }
}

# 步骤 3：创建一个智能体。这里我们以 `Assistant` 智能体为例，它能够使用工具并读取文件。
system_instruction = '''在收到用户的请求后，你应该：
- 首先绘制一幅图像，得到图像的url，
- 然后运行代码`request.get`以下载该图像的url，
- 最后从给定的文档中选择一个图像操作进行图像处理。
用 `plt.show()` 展示图像。
你总是用中文回复用户。'''
tools = ['my_image_gen', 'code_interpreter']  # `code_interpreter` 是框架自带的工具，用于执行代码。
files = ['./examples/resource/doc.pdf']  # 给智能体一个 PDF 文件阅读。
bot = Assistant(llm=llm_cfg,
                system_message=system_instruction,
                function_list=tools,
                files=files)
```

----------------------------------------

TITLE: Configure LLM and initialize Qwen-Agent Assistant
DESCRIPTION: Define the configuration for the Large Language Model (LLM), specifying the model name, server, and API key. Also, configure the MCP tools with the Amap server URL and key. Initialize the `Assistant` agent with the LLM configuration and the list of tools.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/examples/cookbook_drive_guide.ipynb#_snippet_2

LANGUAGE: python
CODE:
```
llm_cfg = {
    'model': 'qwen3-32b',
    'model_server': 'dashscope',
    'api_key': '' # **fill your dashscope api key here**

    # Use a model service compatible with the OpenAI API, such as vLLM or Ollama:
    # 'model': 'Qwen3-8B',
    # 'model_server': 'http://localhost:8000/v1',  # base_url, also known as api_base
    # 'api_key': 'EMPTY'
}

tools = [
    {
        "mcpServers": {
            # enumeration of mcp server configs
            "amap-amap-sse": {
                "url": "https://mcp.amap.com/sse?key=YOUR_KEY" # **fill your amap mcp key**
            }
        }
    }
]

agent = Assistant(
    llm=llm_cfg, 
    function_list=tools
)
```

----------------------------------------

TITLE: Run Agent and Print Response (First Interaction) (Python)
DESCRIPTION: Calls the agent's `run` method with the current message history and iterates through the streaming response, printing it using the `typewriter_print` utility.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/examples/cookbook_mind_map.ipynb#_snippet_6

LANGUAGE: python
CODE:
```
response_plain_text = ''
for ret_messages in agent.run(messages):
    # `ret_messages` will contain all subsequent messages, consisting of interleaved assistant messages and tool responses
    response_plain_text = typewriter_print(ret_messages, response_plain_text)
```

----------------------------------------

TITLE: Initializing and Chatting with Qwen-Agent LLM (Python)
DESCRIPTION: This snippet shows how to configure and obtain an LLM instance using get_chat_model in Qwen-Agent. It sets up a configuration for a DashScope model (qwen-max) and defines a sample user message and a function definition for weather lookup. The code then calls the llm.chat method with messages, functions, and stream=True to demonstrate receiving responses in a streaming fashion, printing each chunk as it arrives.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/docs/llm_cn.md#_snippet_0

LANGUAGE: python
CODE:
```
from qwen_agent.llm import get_chat_model

llm_cfg = {
            # Use the model service provided by DashScope:
            # 'model_type': 'qwen_dashscope',
            'model': 'qwen-max',
            'model_server': 'dashscope',
            # Use your own model service compatible with OpenAI API:
            # 'model': 'Qwen',
            # 'model_server': 'http://127.0.0.1:7905/v1',
            # (Optional) LLM hyper-paramters:
            'generate_cfg': {
                'top_p': 0.8
            }
          }
llm = get_chat_model(llm_cfg)
messages = [{
    'role': 'user',
    'content': "What's the weather like in San Francisco?"
}]
functions = [{
    'name': 'get_current_weather',
    'description': 'Get the current weather in a given location',
    'parameters': {
        'type': 'object',
        'properties': {
            'location': {
                'type': 'string',
                'description':
                'The city and state, e.g. San Francisco, CA',
            },
            'unit': {
                'type': 'string',
                'enum': ['celsius', 'fahrenheit']
            },
        },
        'required': ['location'],
    },
}]

# 此处演示流式输出效果
responses = []
for responses in llm.chat(messages=messages,
                          functions=functions,
                          stream=True):
    print(responses)
```

----------------------------------------

TITLE: Initializing and Using Qwen-Agent LLM with Function Calling (Python)
DESCRIPTION: This snippet demonstrates how to initialize an LLM instance using `get_chat_model` with a configuration dictionary. It shows how to set up messages and function definitions for function calling and then uses the `llm.chat` interface to generate responses, including streaming output.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/docs/llm.md#_snippet_0

LANGUAGE: python
CODE:
```
from qwen_agent.llm import get_chat_model

llm_cfg = {
            # Use the model service provided by DashScope:
            # 'model_type': 'qwen_dashscope',
            'model': 'qwen-max',
            'model_server': 'dashscope',
            # Use your own model service compatible with OpenAI API:
            # 'model': 'Qwen',
            # 'model_server': 'http://127.0.0.1:7905/v1',
            # (Optional) LLM hyper-paramters:
            'generate_cfg': {
                'top_p': 0.8
            }
          }
llm = get_chat_model(llm_cfg)
messages = [{
    'role': 'user',
    'content': "What's the weather like in San Francisco?"
}]
functions = [{
    'name': 'get_current_weather',
    'description': 'Get the current weather in a given location',
    'parameters': {
        'type': 'object',
        'properties': {
            'location': {
                'type': 'string',
                'description':
                'The city and state, e.g. San Francisco, CA',
            },
            'unit': {
                'type': 'string',
                'enum': ['celsius', 'fahrenheit']
            },
        },
        'required': ['location'],
    },
}]

# The streaming output responses
responses = []
for responses in llm.chat(messages=messages,
                          functions=functions,
                          stream=True):
    print(responses)
```

----------------------------------------

TITLE: Configure LLM Backend (Python)
DESCRIPTION: Configures the Large Language Model (LLM) settings for the agent. This dictionary specifies the model name, type (e.g., DashScope or OpenAI-compatible), API key or server URL, and optional generation hyperparameters like `top_p`. It shows configurations for both DashScope and OpenAI-compatible endpoints.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/README.md#_snippet_8

LANGUAGE: Python
CODE:
```
llm_cfg = {
    # Use the model service provided by DashScope:
    'model': 'qwen-max-latest',
    'model_type': 'qwen_dashscope',
    # 'api_key': 'YOUR_DASHSCOPE_API_KEY',
    # It will use the `DASHSCOPE_API_KEY' environment variable if 'api_key' is not set here.

    # Use a model service compatible with the OpenAI API, such as vLLM or Ollama:
    # 'model': 'Qwen2.5-7B-Instruct',
    # 'model_server': 'http://localhost:8000/v1',  # base_url, also known as api_base
    # 'api_key': 'EMPTY',

    # (Optional) LLM hyperparameters for generation:
    'generate_cfg': {
        'top_p': 0.8
    }
}
```

----------------------------------------

TITLE: Configure and Initialize Qwen-Agent (Python)
DESCRIPTION: Sets up the language model configuration and defines the MCP tools (filesystem and sqlite) available to the agent, then initializes the `Assistant` instance.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/examples/cookbook_database_manipulation.ipynb#_snippet_5

LANGUAGE: python
CODE:
```
llm_cfg = {
    'model': 'qwen3-32b',
    'model_server': 'dashscope',
    'api_key': '' # **fill your dashscope api key here**

    # Use a model service compatible with the OpenAI API, such as vLLM or Ollama:
    # 'model': 'Qwen3-8B',
    # 'model_server': 'http://localhost:8000/v1',  # base_url, also known as api_base
    # 'api_key': 'EMPTY'
}

tools = [
    {
        "mcpServers": {
            # enumeration of mcp server configs
            "filesystem": {
                "command": "npx",
                "args": [
                    "-y",
                    "@modelcontextprotocol/server-filesystem",
                    '.',
                ]
            },
            "sqlite" : {
                "command": "uvx",
                "args": [
                    "mcp-server-sqlite",
                    "--db-path",
                    "scores.db"
                ]
            }
        }
    }
]

agent = Assistant(
    llm=llm_cfg,
    function_list=tools
)
```

----------------------------------------

TITLE: Initialize Qwen-Agent with MCP Tools (Python)
DESCRIPTION: Imports necessary classes, defines the LLM configuration (model, server, API key), specifies the MCP servers (filesystem and mindmap) as tools, and initializes the `Assistant` agent.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/examples/cookbook_mind_map.ipynb#_snippet_4

LANGUAGE: python
CODE:
```
from qwen_agent.agents import Assistant
from qwen_agent.utils.output_beautify import typewriter_print
# `typewriter_print` prints streaming messages in a non-overlapping manner.

llm_cfg = {
    'model': 'qwen3-32b',
    'model_server': 'dashscope',
    'api_key': '' # **fill your api key here**

    # Use a model service compatible with the OpenAI API, such as vLLM or Ollama:
    # 'model': 'Qwen3-8B',
    # 'model_server': 'http://localhost:8000/v1',  # base_url, also known as api_base
    # 'api_key': 'EMPTY'
}

tools = [{
    "mcpServers": {
        "filesystem": {
            "command": "npx",
            "args": [
                "-y",
                "@modelcontextprotocol/server-filesystem",
                '.'
            ]
        },
        "mindmap": {
            "command": "uvx",
            "args": ["mindmap-mcp-server", "--return-type", "filePath"]
        }
    }
}]
agent = Assistant(
    llm=llm_cfg,
    function_list=tools
)
```

----------------------------------------

TITLE: Configure LLM Parameters for Qwen-Agent (Python)
DESCRIPTION: A Python dictionary configuration (`llm_cfg`) used to specify the LLM model, service type, API key, and optional generation parameters for the Qwen-Agent.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/README.md#_snippet_14

LANGUAGE: Python
CODE:
```
llm_cfg = {
    # The model name being used:
    'model': 'qwen3-32b',
    # The model service being used:
    'model_type': 'qwen_dashscope',
    # If 'api_key' is not set here, it will default to reading the `DASHSCOPE_API_KEY` environment variable:
    'api_key': 'YOUR_DASHSCOPE_API_KEY',

    # Using an OpenAI API compatible model service, such as vLLM or Ollama:
    # 'model': 'qwen3-32b',
    # 'model_server': 'http://localhost:8000/v1',  # base_url, also known as api_base
    # 'api_key': 'EMPTY',

    # (Optional) LLM hyperparameters:
    'generate_cfg': {
        # This parameter will affect the tool-call parsing logic. Default is False:
          # Set to True: when content is `<think>this is the thought</think>this is the answer`
          # Set to False: when response consists of reasoning_content and content
        # 'thought_in_content': True,

        # tool-call template: default is nous (recommended for qwen3):
        # 'fncall_prompt_type': 'nous'

        # Maximum input length, messages will be truncated if they exceed this length, please adjust according to model API:
        # 'max_input_tokens': 58000

        # Parameters that will be passed directly to the model API, such as top_p, enable_thinking, etc., according to the API specifications:
        # 'top_p': 0.8
    }
}
```

----------------------------------------

TITLE: Install Qwen-Agent with MCP Support (Python/Shell)
DESCRIPTION: Installs the Qwen-Agent library with optional dependencies for GUI, RAG, Code Interpreter, and MCP functionality using pip.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/examples/cookbook_mind_map.ipynb#_snippet_0

LANGUAGE: shell
CODE:
```
!pip3 install -U "qwen-agent[gui,rag,code_interpreter,mcp]"
```

----------------------------------------

TITLE: Install Qwen-Agent with MCP support
DESCRIPTION: Install the Qwen-Agent library using pip, including the optional dependencies required for GUI, RAG, Code Interpreter, and specifically MCP (Map Capability Platform) support.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/examples/cookbook_drive_guide.ipynb#_snippet_0

LANGUAGE: python
CODE:
```
!pip3 install -U "qwen-agent[gui,rag,code_interpreter,mcp]"
# `pip install -U qwen-agent` will install the minimal requirements.
# The optional requirements, specified in double brackets, are:
#   [gui] for Gradio-based GUI support;
#   [rag] for RAG support;
#   [code_interpreter] for Code Interpreter support;
#   [mcp] for MCP support.
```

----------------------------------------

TITLE: Registering a Custom Qwen-Agent Tool (Python)
DESCRIPTION: Shows how to define and register a custom tool (`MyImageGen`) using the `@register_tool` decorator. It inherits from `BaseTool`, defines `description` and `parameters`, and implements the `call` method to process input parameters (parsed from JSON string), encode the prompt, and return a JSON string containing an image URL. Requires `urllib.parse`, `json5`, `json`, and `qwen_agent.tools.base`.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/docs/tool.md#_snippet_1

LANGUAGE: Python
CODE:
```
import urllib.parse
import json5
import json
from qwen_agent.tools.base import BaseTool, register_tool
# Add a custom tool named my_image_gen：
@register_tool('my_image_gen')
class MyImageGen(BaseTool):
    description = 'AI painting (image generation) service, input text description, and return the image URL drawn based on text information.'
    parameters = [{
        'name': 'prompt',
        'type': 'string',
        'description':
        'Detailed description of the desired image content, in English',
        'required': True
    }]

    def call(self, params: str, **kwargs) -> str:
        prompt = json5.loads(params)['prompt']
        prompt = urllib.parse.quote(prompt)
        return json.dumps(
            {'image_url': f'https://image.pollinations.ai/prompt/{prompt}'},
            ensure_ascii=False)
```

----------------------------------------

TITLE: Importing Modules for Custom Agent Development (Python)
DESCRIPTION: Imports necessary Python modules and classes from the Qwen-Agent library and standard libraries. These imports are the initial steps for developing a custom agent, including tools and agent instances.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/README.md#_snippet_6

LANGUAGE: python
CODE:
```
import pprint
import urllib.parse
import json5
from qwen_agent.agents import Assistant
from qwen_agent.tools.base import BaseTool, register_tool
from qwen_agent.utils.output_beautify import typewriter_print

```

----------------------------------------

TITLE: Define Custom Image Generation Tool (Python)
DESCRIPTION: Defines a custom tool named 'my_image_gen' using the Qwen-Agent framework. This tool takes a text prompt as input and returns a URL for a generated image by calling an external image generation service. It uses `json5` for parsing parameters and `urllib.parse` for encoding the prompt.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/README.md#_snippet_7

LANGUAGE: Python
CODE:
```
@register_tool('my_image_gen')
class MyImageGen(BaseTool):
    # The `description` tells the agent the functionality of this tool.
    description = 'AI painting (image generation) service, input text description, and return the image URL drawn based on text information.'
    # The `parameters` tell the agent what input parameters the tool has.
    parameters = [{
        'name': 'prompt',
        'type': 'string',
        'description': 'Detailed description of the desired image content, in English',
        'required': True
    }]

    def call(self, params: str, **kwargs) -> str:
        # `params` are the arguments generated by the LLM agent.
        prompt = json5.loads(params)['prompt']
        prompt = urllib.parse.quote(prompt)
        return json5.dumps(
            {'image_url': f'https://image.pollinations.ai/prompt/{prompt}'},
            ensure_ascii=False)
```

----------------------------------------

TITLE: Implementing DocQA Agent with _call_llm (Python)
DESCRIPTION: This Python class `DocQA` illustrates a non-nested approach to creating a custom agent for Document Question Answering. It utilizes the base `_call_llm` method to interact with the language model. The workflow involves formatting a system message by incorporating provided `knowledge` (reference documents) into a predefined prompt template and then passing the modified messages to the LLM.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/docs/agent_cn.md#_snippet_1

LANGUAGE: Python
CODE:
```
import copy
from typing import Iterator, List

from qwen_agent import Agent
from qwen_agent.llm.schema import CONTENT, ROLE, SYSTEM, Message

PROMPT_TEMPLATE_ZH = """
请充分理解以下参考资料内容，组织出满足用户提问的条理清晰的回复。
#参考资料：
{ref_doc}

"""

PROMPT_TEMPLATE_EN = """
Please fully understand the content of the following reference materials and organize a clear response that meets the user's questions.
# Reference materials:
{ref_doc}

"""

PROMPT_TEMPLATE = {
    'zh': PROMPT_TEMPLATE_ZH,
    'en': PROMPT_TEMPLATE_EN,
}


class DocQA(Agent):

    def _run(self,
             messages: List[Message],
             knowledge: str = '',
             lang: str = 'en',
             **kwargs) -> Iterator[List[Message]]:
        messages = copy.deepcopy(messages)
        system_prompt = PROMPT_TEMPLATE[lang].format(ref_doc=knowledge)
        if messages and messages[0][ROLE] == SYSTEM:
            messages[0][CONTENT] += system_prompt
        else:
            messages.insert(0, Message(SYSTEM, system_prompt))

        return self._call_llm(messages=messages)
```

----------------------------------------

TITLE: Defining Custom Agent with Nested Agents (Python)
DESCRIPTION: This Python class `VisualStorytelling` demonstrates how to create a custom agent by nesting other agents. It is designed to generate stories from images by using an `image_agent` (based on Qwen-VL) for image understanding and a `writing_agent` for generating the narrative. The `_run` method orchestrates the workflow, first getting an image description and then using it to prompt the writing agent.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/docs/agent_cn.md#_snippet_0

LANGUAGE: Python
CODE:
```
import copy
from typing import Dict, Iterator, List, Optional, Union

from qwen_agent import Agent
from qwen_agent.agents import Assistant
from qwen_agent.llm import BaseChatModel
from qwen_agent.llm.schema import ContentItem, Message
from qwen_agent.tools import BaseTool

class VisualStorytelling(Agent):
    """Customize an agent for writing story from pictures"""

    def __init__(self,
                 function_list: Optional[List[Union[str, Dict,
                                                    BaseTool]]] = None,
                 llm: Optional[Union[Dict, BaseChatModel]] = None):
        super().__init__(llm=llm)

        # Nest one vl assistant for image understanding
        self.image_agent = Assistant(llm={'model': 'qwen-vl-max'})

        # Nest one assistant for article writing
        self.writing_agent = Assistant(
            llm=self.llm,
            function_list=function_list,
            system_message='你扮演一个想象力丰富的学生，你需要先理解图片内容，根据描述图片信息以后，' +
            '参考知识库中教你的写作技巧，发挥你的想象力，写一篇800字的记叙文',
            files=['https://www.jianshu.com/p/cdf82ff33ef8'])

    def _run(self,
             messages: List[Message],
             lang: str = 'zh',
             max_ref_token: int = 4000,
             **kwargs) -> Iterator[List[Message]]:
        """Define the workflow"""

        assert isinstance(messages[-1]['content'], list) and any([
            item.image for item in messages[-1]['content']
        ]), 'This agent requires input of images'

        # Image understanding
        new_messages = copy.deepcopy(messages)
        new_messages[-1]['content'].append(
            ContentItem(text='请详细描述这张图片的所有细节内容'))
        response = []
        for rsp in self.image_agent.run(new_messages):
            yield response + rsp
        response.extend(rsp)
        new_messages.extend(rsp)

        # Writing article
        new_messages.append(Message('user', '开始根据以上图片内容编写你的记叙文吧！'))
        for rsp in self.writing_agent.run(new_messages,
                                          lang=lang,
                                          max_ref_token=max_ref_token,
                                          **kwargs):
            yield response + rsp
```

----------------------------------------

TITLE: Calling Qwen-Agent ImageGen Tool Directly (Python)
DESCRIPTION: Demonstrates how to directly instantiate and call a Qwen-Agent tool (`ImageGen`) externally using its `.call()` interface. It shows passing parameters as a dictionary and printing the result. The tool expects a dictionary with a 'prompt' key.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/docs/tool.md#_snippet_0

LANGUAGE: Python
CODE:
```
from qwen_agent.tools import ImageGen

tool = ImageGen()
res = tool.call(params = {'prompt': 'a cute cat'})
print(res)
```

----------------------------------------

TITLE: Installing Qwen-Agent with Minimal Dependencies (Bash)
DESCRIPTION: Installs the Qwen-Agent library from PyPI with only the minimal required dependencies. Use this if you don't need the optional features like GUI, RAG, Code Interpreter, or MCP.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/README.md#_snippet_1

LANGUAGE: bash
CODE:
```
pip install -U qwen-agent
```

----------------------------------------

TITLE: Install Qwen-Agent with MCP (Python)
DESCRIPTION: Installs or updates the Qwen-Agent library via pip, including necessary optional dependencies like MCP support for filesystem and database operations.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/examples/cookbook_database_manipulation.ipynb#_snippet_0

LANGUAGE: python
CODE:
```
!pip3 install -U "qwen-agent[gui,rag,code_interpreter,mcp]"
```

----------------------------------------

TITLE: Installing Qwen-Agent with Minimal Dependencies (Bash)
DESCRIPTION: This command installs the latest stable version of the qwen-agent package from PyPI with only the core dependencies. Optional features require specifying extra packages in brackets.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/README_CN.md#_snippet_1

LANGUAGE: bash
CODE:
```
pip install -U qwen-agent
```

----------------------------------------

TITLE: Import Qwen-Agent Modules (Python)
DESCRIPTION: Imports the `Assistant` class for agent creation and `typewriter_print` utility for displaying streaming output from the agent.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/examples/cookbook_database_manipulation.ipynb#_snippet_4

LANGUAGE: python
CODE:
```
from qwen_agent.agents import Assistant
from qwen_agent.utils.output_beautify import typewriter_print
# `typewriter_print` prints streaming messages in a non-overlapping manner for a clear view.
```

----------------------------------------

TITLE: Launch Gradio Web UI for Agent (Python)
DESCRIPTION: Provides a simple way to launch a Gradio-based web user interface for an existing Qwen-Agent instance. This allows interacting with the agent through a browser-based chat interface instead of the command line.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/README.md#_snippet_10

LANGUAGE: Python
CODE:
```
from qwen_agent.gui import WebUI
WebUI(bot).run()  # bot is the agent defined in the above code, we do not repeat the definition here for saving space.
```

----------------------------------------

TITLE: Defining a Custom Qwen-Agent Tool Without Registration (Python)
DESCRIPTION: Illustrates how to define a custom tool (`MyImageGen`) by inheriting from `BaseTool` and manually setting the `name`, `description`, and `parameters` attributes, along with implementing the `call` method. This method does not use the `@register_tool` decorator. The `call` method processes input parameters (parsed from JSON string), encodes the prompt, and returns a JSON string containing an image URL. Requires `urllib.parse`, `json5`, `json`, and `qwen_agent.tools.base`. This approach is used when passing the tool object directly to the Agent.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/docs/tool.md#_snippet_2

LANGUAGE: Python
CODE:
```
import urllib.parse
import json5
import json
from qwen_agent.tools.base import BaseTool

class MyImageGen(BaseTool):
    name = 'my_image_gen'
    description = 'AI painting (image generation) service, input text description, and return the image URL drawn based on text information.'
    parameters = [{
        'name': 'prompt',
        'type': 'string',
        'description':
        'Detailed description of the desired image content, in English',
        'required': True
    }]

    def call(self, params: str, **kwargs) -> str:
        prompt = json5.loads(params)['prompt']
        prompt = urllib.parse.quote(prompt)
        return json.dumps(
            {'image_url': f'https://image.pollinations.ai/prompt/{prompt}'},
            ensure_ascii=False)
```

----------------------------------------

TITLE: Launching Web UI for Qwen-Agent (Python)
DESCRIPTION: This snippet demonstrates how to initialize an `Assistant` agent and then launch a web-based graphical user interface for it using the `WebUI` class from `qwen_agent.gui`. It requires a pre-configured `llm_cfg` and `tools` list for the agent.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/examples/cookbook_database_manipulation.ipynb#_snippet_14

LANGUAGE: python
CODE:
```
from qwen_agent.gui import WebUI

agent = Assistant(
    name="Qwen Assistant",
    description="I'm a digital assistant powered by Qwen-Agent, ask me anything!",
    llm=llm_cfg,
    function_list=tools
)

WebUI(agent).run()
# Have fun!
```

----------------------------------------

TITLE: Update message context with agent response
DESCRIPTION: Append the response messages received from the agent (`ret_messages`) to the existing `messages` list. This step is crucial for maintaining the conversation context, allowing the agent to understand follow-up questions based on previous interactions.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/examples/cookbook_drive_guide.ipynb#_snippet_5

LANGUAGE: python
CODE:
```
messages += ret_messages # extending the context with new `ret_messages`.
```

----------------------------------------

TITLE: Update Message History (First Interaction) (Python)
DESCRIPTION: Appends the messages returned by the agent's last run (including tool calls and responses) to the main message history list.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/examples/cookbook_mind_map.ipynb#_snippet_7

LANGUAGE: python
CODE:
```
messages += ret_messages
```

----------------------------------------

TITLE: Run Qwen-Agent Web UI (Python)
DESCRIPTION: Initializes the `Assistant` agent with a name, description, LLM configuration, and tools, then starts a Gradio-based web user interface for interacting with the agent.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/examples/cookbook_mind_map.ipynb#_snippet_10

LANGUAGE: python
CODE:
```
from qwen_agent.gui import WebUI

agent = Assistant(
    name="Qwen File Processing Assistant",
    description="I can help with your file processing needs, ask me anything!",
    llm=llm_cfg,
    function_list=tools
)

WebUI(agent).run()
```

----------------------------------------

TITLE: Run Agent and Print Response (Second Interaction) (Python)
DESCRIPTION: Calls the agent's `run` method again with the updated message history and prints the streaming response for the mind map creation task.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/examples/cookbook_mind_map.ipynb#_snippet_9

LANGUAGE: python
CODE:
```
response_plain_text = ''
for ret_messages in agent.run(messages):
    # `ret_messages` will contain all subsequent messages, consisting of interleaved assistant messages and tool responses
    response_plain_text = typewriter_print(ret_messages, response_plain_text)
```

----------------------------------------

TITLE: Installing Qwen-Agent from Source with Full Optional Dependencies (Bash)
DESCRIPTION: Installs the Qwen-Agent library in editable mode (`-e`) from the local source directory, including all optional dependencies. This is used for development or using the latest unreleased features.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/README.md#_snippet_4

LANGUAGE: bash
CODE:
```
pip install -e ./"[gui,rag,code_interpreter,mcp]"
```

----------------------------------------

TITLE: Installing Qwen-Agent from Source (Editable, Full) (Bash)
DESCRIPTION: This command installs the qwen-agent package directly from the local source directory in editable mode (`-e`), including all optional dependencies. Editable mode allows changes to the source code to be reflected without reinstalling.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/README_CN.md#_snippet_4

LANGUAGE: bash
CODE:
```
pip install -e ./"[gui,rag,code_interpreter,mcp]"
```

----------------------------------------

TITLE: Run Agent to Query Database (Python)
DESCRIPTION: Executes the agent with the final history and prints the streaming response containing the result of the database query.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/examples/cookbook_database_manipulation.ipynb#_snippet_13

LANGUAGE: python
CODE:
```
response_plain_text = ''

for ret_messages in agent.run(messages):
    response_plain_text = typewriter_print(ret_messages, response_plain_text)
```

----------------------------------------

TITLE: Installing Qwen-Agent from Source with Minimal Dependencies (Bash)
DESCRIPTION: Installs the Qwen-Agent library in editable mode (`-e`) from the local source directory with only the minimal required dependencies. Use this for development if you only need the core features.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/README.md#_snippet_5

LANGUAGE: bash
CODE:
```
pip install -e ./
```

----------------------------------------

TITLE: Installing Qwen-Agent from Source (Editable, Minimal) (Bash)
DESCRIPTION: This command installs the qwen-agent package directly from the local source directory in editable mode (`-e`) with only the core dependencies.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/README_CN.md#_snippet_5

LANGUAGE: bash
CODE:
```
pip install -e ./
```

----------------------------------------

TITLE: Launch Qwen-Agent GUI
DESCRIPTION: Initialize the `Assistant` agent with a specific name and description for the GUI interface, using the same LLM configuration and tools. Create a `WebUI` instance with the agent and call its `run` method to start the Gradio-based graphical user interface.
SOURCE: https://github.com/qwenlm/qwen-agent/blob/main/examples/cookbook_drive_guide.ipynb#_snippet_8

LANGUAGE: python
CODE:
```
from qwen_agent.gui import WebUI

agent = Assistant(
    name="Qwen Guide",
    description="I can help with your travel needs, ask me anything!",
    llm=llm_cfg,
    function_list=tools
)

WebUI(agent).run()
```